<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Justin Naldzin - GitHub Repos</title><link href="http://justinnaldzin.github.io/" rel="alternate"></link><link href="http://justinnaldzin.github.io/feeds/github-repos.atom.xml" rel="self"></link><id>http://justinnaldzin.github.io/</id><updated>2017-05-01T00:00:00-04:00</updated><entry><title>Big Data Benchmarking</title><link href="http://justinnaldzin.github.io/big-data-benchmarking.html" rel="alternate"></link><published>2017-05-01T00:00:00-04:00</published><updated>2017-05-01T00:00:00-04:00</updated><author><name>Justin Naldzin</name></author><id>tag:justinnaldzin.github.io,2017-05-01:/big-data-benchmarking.html</id><summary type="html">&lt;p&gt;This is a portable, reproducible, and completely automated application designed to benchmark various database platforms and big data technologies with a goal of comparing how each performs when working with large datasets.  By ensuring the same dataset is inserted into each database platform and executing syntactically equivalent queries, we can achieve an accurate comparison and understand where one outperforms the other.  An interactive HTTP dashboard containing various charting and graphing elements are used to display the benchmarking results for visual analysis.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;This is a portable, reproducible, and completely automated application designed to benchmark various database platforms and big data technologies with a goal of comparing how each performs when working with large datasets.  By ensuring the same dataset is inserted into each database platform and executing syntactically equivalent queries, we can achieve an accurate comparison and understand where one outperforms the other.  An interactive HTTP dashboard containing various charting and graphing elements are used to display the benchmarking results for visual analysis.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;img src="images/benchmarking.jpg" alt="Benchmarking"&gt;
&lt;img src="images/big-data.jpg" alt="Big Data"&gt;
&lt;/p&gt;

&lt;h2&gt;Audience&lt;/h2&gt;
&lt;p&gt;When it comes to Big Data and the platforms that house the data, the most common question being asked is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Which big data platform performs best?"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The answer really depends on a few key factors:
- Raw data size (small data vs. big data)
- Query complexity (joins, unions, aggregate and analytical queries)
- Number of concurrent users
- Memory, CPU, and network configurations&lt;/p&gt;
&lt;p&gt;And since each environment is different, the more appropriate question to ask is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Which performs best under each scenario?"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;If your organization is running multiple Big Data platforms, this benchmarking application is designed to compare them side by side.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="dashboard1" src="images/dashboard1.jpg" title="Dashboard Example"&gt;&lt;/p&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Supports the following big data technologies:&lt;ul&gt;
&lt;li&gt;Oracle Database&lt;/li&gt;
&lt;li&gt;Oracle Database In-Memory&lt;/li&gt;
&lt;li&gt;Microsoft SQL Server&lt;/li&gt;
&lt;li&gt;SAP HANA&lt;/li&gt;
&lt;li&gt;coming soon:&lt;ul&gt;
&lt;li&gt;Apache Hive&lt;/li&gt;
&lt;li&gt;Apache Spark SQL&lt;/li&gt;
&lt;li&gt;SQLite (use pysqlite)&lt;/li&gt;
&lt;li&gt;MySQL (use mysqldb or mysql.connector or pymysql)&lt;/li&gt;
&lt;li&gt;MariaDB (use mysqldb or mysql.connector or pymysql)&lt;/li&gt;
&lt;li&gt;PostgreSQL (use psycopg2)&lt;/li&gt;
&lt;li&gt;Microsoft Azure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compatible on Linux, macOS, and Windows in a reproducible, portable development environment&lt;/li&gt;
&lt;li&gt;Able to accept multiple source datasets in CSV file format (containing headers)&lt;/li&gt;
&lt;li&gt;Create tables and insert into database the datasets specified&lt;/li&gt;
&lt;li&gt;Run benchmarks on these new datasets or on existing tables in the database&lt;/li&gt;
&lt;li&gt;Able to specify the name of the tables to benchmark&lt;/li&gt;
&lt;li&gt;Able to specify the number of benchmarking iterations to perform&lt;/li&gt;
&lt;li&gt;Able to specify the number of concurrent users to simultaneously perform the same benchmarking queries&lt;/li&gt;
&lt;li&gt;Predefined query templates used to formulate a dynamically generated query which is transferrable between each database technology using a syntactically equivalent query&lt;/li&gt;
&lt;li&gt;Limit query results to a specified row count&lt;/li&gt;
&lt;li&gt;Drop tables (only on the newly created tables) immediately after the benchmark&lt;/li&gt;
&lt;li&gt;Output benchmarking results to CSV&lt;/li&gt;
&lt;li&gt;Plot the results in an interactive HTML dashboard containing data tables, charts and graphs using a &lt;a href="http://bokeh.pydata.org/"&gt;Bokeh&lt;/a&gt; server web app&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt; - A tool for building complete development environments&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt; - A cross-platform virtualization application&lt;/li&gt;
&lt;li&gt;Read/Write permissions to one or more of the following database technologies:&lt;ul&gt;
&lt;li&gt;Oracle Database&lt;/li&gt;
&lt;li&gt;Oracle Database In-Memory&lt;/li&gt;
&lt;li&gt;Microsoft SQL Server&lt;/li&gt;
&lt;li&gt;SAP HANA&lt;/li&gt;
&lt;li&gt;more coming soon...&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;One or more CSV datasets (containing headers).  Recommended sites to find open datasets:&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.data.gov"&gt;data.gov&lt;/a&gt; - The home of the U.S. Government's open data&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/datasets/"&gt;/r/datasets&lt;/a&gt; - subreddit with hundreds of interesting datasets&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/caesar0301/awesome-public-datasets"&gt;Awesome Public Datasets&lt;/a&gt; - list of datasets, hosted on GitHub.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.kaggle.com/datasets"&gt;Kaggle&lt;/a&gt; - Kaggle datasets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Download and install the latest versions of:
- &lt;a href="https://www.vagrantup.com/docs/installation/"&gt;Vagrant&lt;/a&gt;
- &lt;a href="https://www.virtualbox.org/"&gt;VirtualBox&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Install the Vagrant plugin which automatically installs the host's VirtualBox Guest Additions on the guest system&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vagrant plugin install vagrant-vbguest
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Clone the repo and navigate into the project directory&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/justinnaldzin/big-data-benchmarking.git
&lt;span class="nb"&gt;cd&lt;/span&gt; big-data-benchmarking
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The folder structure looks like the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ tree -L &lt;span class="m"&gt;1&lt;/span&gt;
.
├── LICENSE.md
├── README.md
├── app
├── benchmark.py
├── big_data_benchmarking.py
├── config.json.example
├── create_tables.py
├── csv
├── data
├── drop_tables.py
├── log
├── queries
└── vagrant

&lt;span class="m"&gt;6&lt;/span&gt; directories, &lt;span class="m"&gt;7&lt;/span&gt; files
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Move all source CSV datasets into the &lt;code&gt;big-data-benchmarking/data/&lt;/code&gt; path&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mv /path/to/datasets/*.csv data/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using the example configuration file, create a JSON file named &lt;code&gt;config.json&lt;/code&gt; and add database credentials to the &lt;code&gt;connection_string&lt;/code&gt; parameter&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cp config.json.example config.json
vi config.json
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;connection_string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;oracle+cx_oracle://user:password@host&amp;quot;&lt;/span&gt;
        &lt;span class="err"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;Oracle Database In-Memory&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;connection_string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;oracle+cx_oracle://user:password@host&amp;quot;&lt;/span&gt;
        &lt;span class="err"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;SQL Server&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;connection_string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mssql+pymssql://user:password@host&amp;quot;&lt;/span&gt;
        &lt;span class="err"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;HANA&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;connection_string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hana://user:password@host:30015&amp;quot;&lt;/span&gt;
        &lt;span class="err"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;quot;Hive&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:{&lt;/span&gt;
        &lt;span class="nt"&gt;&amp;quot;connection_string&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hive://user:password@host:10000/database&amp;quot;&lt;/span&gt;
        &lt;span class="err"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Build the environment in a virtual machine&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; vagrant
vagrant up
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After provisioning, SSH into the VM&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vagrant ssh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Navigate to the project directory on the VM&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /big-data-benchmarking
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Print the command line help menu to view all the options for running the application&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./big_data_benchmarking.py --help
usage: big_data_benchmarking.py &lt;span class="o"&gt;[&lt;/span&gt;-h&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-t TABLE_LIKE&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-r ROWS&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-i ITERATIONS&lt;span class="o"&gt;]&lt;/span&gt;
                                &lt;span class="o"&gt;[&lt;/span&gt;-u CONCURRENT_USERS&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-p DATA_PATH&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-c&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;-d&lt;span class="o"&gt;]&lt;/span&gt;
                                &lt;span class="o"&gt;[&lt;/span&gt;database_list &lt;span class="o"&gt;[&lt;/span&gt;database_list ...&lt;span class="o"&gt;]]&lt;/span&gt;

Big Data Benchmarking

positional arguments:
  database_list         Specify the list of Databases to benchmark. These
                        names must match the names pre-configured in the
                        &lt;span class="s1"&gt;&amp;#39;config.json&amp;#39;&lt;/span&gt; file.

optional arguments:
  -h, --help            show this &lt;span class="nb"&gt;help&lt;/span&gt; message and &lt;span class="nb"&gt;exit&lt;/span&gt;
  -t TABLE_LIKE, --table-like TABLE_LIKE
                        Specify the name of the tables to benchmark. This uses
                        the SQL &lt;span class="s1"&gt;&amp;#39;LIKE&amp;#39;&lt;/span&gt; operator to search a specified pattern
                        so use the &lt;span class="s1"&gt;&amp;#39;%&amp;#39;&lt;/span&gt; sign to define wildcards. Default is
                        &lt;span class="s1"&gt;&amp;#39;%&amp;#39;&lt;/span&gt; which will find all existing tables in the
                        database.
  -r ROWS, --rows ROWS  The maximum number of rows to &lt;span class="k"&gt;return&lt;/span&gt; from each query
                        execution. Default is &lt;span class="m"&gt;10000&lt;/span&gt;
  -i ITERATIONS, --iterations ITERATIONS
                        The number of benchmark iterations to perform on the
                        database. Default is &lt;span class="m"&gt;1&lt;/span&gt;
  -u CONCURRENT_USERS, --users CONCURRENT_USERS
                        The number of concurrent users to connect to the
                        database. Default is &lt;span class="m"&gt;1&lt;/span&gt;
  -p DATA_PATH, --path DATA_PATH
                        Full directory path to where the data files are
                        stored. These will be used to create the tables and
                        insert into database. Default path is: /data
  -c, --create-tables   Create tables and insert into database the data files
                        that exist within in the folder &lt;span class="s1"&gt;&amp;#39;--path&amp;#39;&lt;/span&gt; argument. Not
                        specifying this option will run benchmarks on all
                        existing tables in the database.
  -d, --drop-tables     The &lt;span class="s1"&gt;&amp;#39;--create-tables&amp;#39;&lt;/span&gt; argument must be specified. Only
                        those tables created will be dropped.
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Benchmarking&lt;/h2&gt;
&lt;div class="alert alert-info"&gt;
  &lt;strong&gt;Note!&lt;/strong&gt; If you simply want to view the interactive dashboard using sample benchmarking results, skip this section and jump down to the [Benchmarking Results](#benchmarking-results) section.
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;big-data-benchmarking.py&lt;/code&gt; Python script is the main entrypoint to the application.  Here are some example benchmarking scenarios, and how to execute the script:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run against &lt;strong&gt;Oracle Database&lt;/strong&gt; and &lt;strong&gt;SQL Server&lt;/strong&gt; with default options&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SQL Server&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Run on &lt;strong&gt;Oracle Database In-Memory&lt;/strong&gt; against all tables whose name starts with "DEV"&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database In-Memory&amp;quot;&lt;/span&gt; -t &lt;span class="s2"&gt;&amp;quot;DEV%&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Run against &lt;strong&gt;HANA&lt;/strong&gt; limiting the number of rows to return from each query to &lt;strong&gt;5000&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;HANA&amp;quot;&lt;/span&gt; -r &lt;span class="m"&gt;5000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Run with &lt;strong&gt;50&lt;/strong&gt; concurrent users&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt; -u &lt;span class="m"&gt;50&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Run &lt;strong&gt;10&lt;/strong&gt; iterations&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt; -i &lt;span class="m"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Create tables on the database using all CSV datasets in the default &lt;code&gt;/big-data-benchmarking/data/&lt;/code&gt; path&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt; -c
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Create tables specifying a different directory than the default path where the CSV datasets reside&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt; -c -p /some/other/path/
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Create tables and drop only those tables after the benchmark completes&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./big-data-benchmarking.py &lt;span class="s2"&gt;&amp;quot;Oracle Database&amp;quot;&lt;/span&gt; -c -d
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Benchmarking Results&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;/big-data-benchmarking/csv/&lt;/code&gt; is the location where the actual benchmarking results are written to.  Within this folder you will also find an example benchmarking results CSV file.  This example allows full functionality of the Bokeh server web application even without running any benchmarks.&lt;/p&gt;
&lt;p&gt;Here is a sample of what the CSV data looks like:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;category&lt;/th&gt;
&lt;th&gt;concurrency_factor&lt;/th&gt;
&lt;th&gt;database&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;query_executed&lt;/th&gt;
&lt;th&gt;query_id&lt;/th&gt;
&lt;th&gt;query_template&lt;/th&gt;
&lt;th&gt;rows&lt;/th&gt;
&lt;th&gt;table_name&lt;/th&gt;
&lt;th&gt;table_row_count&lt;/th&gt;
&lt;th&gt;table_size_category&lt;/th&gt;
&lt;th&gt;time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Aggregate&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Oracle Database&lt;/td&gt;
&lt;td&gt;COUNT *&lt;/td&gt;
&lt;td&gt;SELECT COUNT(*) FROM "On_Time_Performance_ALL"&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td table&gt;SELECT COUNT(*) FROM &lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;On_Time_Performance_ALL&lt;/td&gt;
&lt;td&gt;160690563&lt;/td&gt;
&lt;td&gt;X-Large&lt;/td&gt;
&lt;td&gt;149.38998920100005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aggregate&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Oracle Database&lt;/td&gt;
&lt;td&gt;COUNT&lt;/td&gt;
&lt;td&gt;SELECT COUNT("LATE_AIRCRAFT_DELAY") FROM "On_Time_Performance_ALL"&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td numeric_column&gt;SELECT COUNT(&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;On_Time_Performance_ALL&lt;/td&gt;
&lt;td&gt;160690563&lt;/td&gt;
&lt;td&gt;X-Large&lt;/td&gt;
&lt;td&gt;144.099790143&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aggregate&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Oracle Database&lt;/td&gt;
&lt;td&gt;COUNT DISTINCT&lt;/td&gt;
&lt;td&gt;SELECT COUNT(DISTINCT "DEST_CITY_MARKET_ID") FROM "On_Time_Performance_ALL"&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td numeric_column&gt;SELECT COUNT(DISTINCT &lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;On_Time_Performance_ALL&lt;/td&gt;
&lt;td&gt;160690563&lt;/td&gt;
&lt;td&gt;X-Large&lt;/td&gt;
&lt;td&gt;156.50899973100002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aggregate&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Oracle Database&lt;/td&gt;
&lt;td&gt;SUM&lt;/td&gt;
&lt;td&gt;SELECT SUM("WHEELS_OFF") FROM "On_Time_Performance_ALL"&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td numeric_column&gt;SELECT SUM(&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;On_Time_Performance_ALL&lt;/td&gt;
&lt;td&gt;160690563&lt;/td&gt;
&lt;td&gt;X-Large&lt;/td&gt;
&lt;td&gt;156.93902191200004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Aggregate&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Oracle Database&lt;/td&gt;
&lt;td&gt;SUM DISTINCT&lt;/td&gt;
&lt;td&gt;SELECT SUM(DISTINCT "LATE_AIRCRAFT_DELAY") FROM "On_Time_Performance_ALL"&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td numeric_column&gt;SELECT SUM(DISTINCT &lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;On_Time_Performance_ALL&lt;/td&gt;
&lt;td&gt;160690563&lt;/td&gt;
&lt;td&gt;X-Large&lt;/td&gt;
&lt;td&gt;149.11920515500003&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Bokeh Server Web App&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://bokeh.pydata.org/"&gt;Bokeh&lt;/a&gt; is a Python interactive visualization library that targets modern web browsers for presentation.  The Bokeh server web app uses the data from the CSV and generates an interactive HTML dashboard consisting of data tables, charts and graphs.  This allows us to visually analyze the benchmarking results and compare each database platform.&lt;/p&gt;
&lt;p&gt;Instruct Bokeh server to launch the web app&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bokeh serve app
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then open your browser and navigate to the dashboard:  http://localhost:5006&lt;/p&gt;
&lt;p&gt;&lt;img alt="dashboard2" src="images/dashboard2.jpg" title="Dashboard Example"&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Finally, when you are finished running the benchmarks and no longer need to view the dashboard results, terminate the VM&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vagrant destroy
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="alert alert-info"&gt;
  &lt;strong&gt;Note!&lt;/strong&gt; The `big-data-benchmarking` project folder remains on your local system, along with the CSV benchmarking results.  You will no longer be able to run the benchmarks or view the dashboard once the VM is terminated.  You can easily reprovision the VM and start over
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vagrant up
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Feature Requests&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Option to specify the &lt;em&gt;minimum&lt;/em&gt; amount of rows to return from each query.  Currently you are only permitted to limit the &lt;em&gt;maximum&lt;/em&gt; amount of rows&lt;/li&gt;
&lt;li&gt;Benchmark different python drivers against the same database type (MySQL example: &lt;code&gt;mysqldb&lt;/code&gt; vs &lt;code&gt;mysql.connector&lt;/code&gt; vs &lt;code&gt;pymysql&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Embed Bokeh into Flask app with Jinja templates&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Author&lt;/h2&gt;
&lt;p&gt;Justin Naldzin - &lt;a href="https://github.com/justinnaldzin"&gt;GitHub&lt;/a&gt;&lt;/p&gt;</content><category term="big data"></category><category term="benchmarking"></category><category term="vagrant"></category><category term="spark"></category><category term="python"></category><category term="jupyter"></category><category term="bokeh"></category><category term="oracle"></category><category term="sql server"></category><category term="hana"></category></entry></feed>